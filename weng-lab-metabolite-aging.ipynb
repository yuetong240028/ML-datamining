{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos=pd.read_excel(\"C:/Users/RAZER/Desktop/DataPreprocessing_pos.xlsx\")\n",
    "df_neg=pd.read_excel(\"C:/Users/RAZER/Desktop/DataPreprocessing_neg.xlsx\")\n",
    "df_pos_T=pd.concat([df_pos.iloc[:,0:1],df_pos.iloc[:,24:40]],axis=1).T\n",
    "df_pos_T.columns= df_pos_T.iloc[0].values\n",
    "df_pos_T=df_pos_T[1:]\n",
    "df_pos_T[\"label\"]=[1]*8+[0]*8\n",
    "df_neg_T=pd.concat([df_neg.iloc[:,0:1],df_neg.iloc[:,24:40]],axis=1).T\n",
    "df_neg_T.columns= df_neg_T.iloc[0].values\n",
    "df_neg_T=df_neg_T[1:]\n",
    "df_neg_T[\"label\"]=[1]*8+[0]*8\n",
    "x_neg=df_neg_T.iloc[:,:-1]\n",
    "y_neg=df_neg_T[\"label\"]\n",
    "x_pos=df_pos_T.iloc[:,:-1]\n",
    "y_pos=df_pos_T[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统分类算法（neg）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  7  8  9 10 11 13 14 15] [ 4 12]\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  0.5\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "[ 0  1  2  3  4  6  7  8  9 11 12 13 14 15] [ 5 10]\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "[ 0  1  2  3  4  5  6  8  9 10 12 13 14 15] [ 7 11]\n",
      "Logistic_Regression： 0.5\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  0.5\n",
      "Random Forest Classifier:  0.5\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 15] [13 14]\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "[ 0  1  4  5  6  7  8  9 10 11 12 13 14 15] [2 3]\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "[ 0  1  2  3  4  5  7  8 10 11 12 13 14 15] [6 9]\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14] [ 0 15]\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "[ 0  2  3  4  5  6  7  9 10 11 12 13 14 15] [1 8]\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  0.5\n",
      "Random Forest Classifier:  1.0\n",
      "The mean accuracy of Logistic_Regression (negative): 0.9375\n",
      "The mean accuracy of Gaussian Navie Bayes (negative): 0.9375\n",
      "The mean accuracy of Support Vector Classifier (negative): 0.875\n",
      "The mean accuracy of Random Forest Classifier (negative): 0.9375\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=8,shuffle=True)\n",
    "LR_acc=[]\n",
    "GNB_acc=[]\n",
    "SVM_acc=[]\n",
    "RF_acc=[]\n",
    "for train_index, test_index in kf.split(x_neg):\n",
    "    print(train_index,test_index)\n",
    "    x_neg_train=x_neg.iloc[list(train_index)]\n",
    "    x_neg_test=x_neg.iloc[list(test_index)]\n",
    "    y_neg_train=y_neg.iloc[list(train_index)]\n",
    "    y_neg_test=y_neg.iloc[list(test_index)]\n",
    "#   LR\n",
    "    logistic_model = LogisticRegression(solver=\"liblinear\").fit(x_neg_train, y_neg_train)\n",
    "    logistic_y_pred = logistic_model.predict(x_neg_test)\n",
    "    logistic_acc=accuracy_score(logistic_y_pred, y_neg_test)\n",
    "    print(\"Logistic_Regression：\",logistic_acc)\n",
    "    LR_acc.append(logistic_acc)\n",
    "# 贝叶斯\n",
    "    gaussian_model = GaussianNB().fit(x_neg_train, y_neg_train)\n",
    "    gaussian_y_pred = gaussian_model.predict(x_neg_test)\n",
    "    gaussian_acc=accuracy_score(gaussian_y_pred, y_neg_test)\n",
    "    print(\"Gaussian Navie Bayes: \",gaussian_acc)\n",
    "    GNB_acc.append(gaussian_acc)\n",
    "# 支持向量机\n",
    "    svc_model = SVC(kernel=\"linear\").fit(x_neg_train, y_neg_train)\n",
    "    svc_y_pred = svc_model.predict(x_neg_test)\n",
    "    support_vector_acc=accuracy_score(svc_y_pred, y_neg_test)\n",
    "    print(\"Support Vector Classifier: \",support_vector_acc)\n",
    "    SVM_acc.append(support_vector_acc)\n",
    "# Random Forest\n",
    "    randomForest_model = RandomForestClassifier(n_estimators=12).fit(x_neg_train, y_neg_train)\n",
    "    randomForest_y_pred = randomForest_model.predict(x_neg_test)\n",
    "    random_forest_acc=accuracy_score(randomForest_y_pred, y_neg_test)\n",
    "    print(\"Random Forest Classifier: \",random_forest_acc)\n",
    "    RF_acc.append(random_forest_acc)\n",
    "print(\"The mean accuracy of Logistic_Regression (negative):\",np.mean(LR_acc))\n",
    "print(\"The mean accuracy of Gaussian Navie Bayes (negative):\",np.mean(GNB_acc))\n",
    "print(\"The mean accuracy of Support Vector Classifier (negative):\",np.mean(SVM_acc))\n",
    "print(\"The mean accuracy of Random Forest Classifier (negative):\",np.mean(RF_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度权重-neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测类别1的重要性top10特征索引: [330, 449, 122, 809, 867, 870, 893, 906, 900, 305] \n",
      "预测类别0的重要性top10特征索引 [897, 357, 123, 131, 360, 428, 874, 383, 797, 276]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "logistic_model = LogisticRegression(solver=\"liblinear\").fit(x_neg, y_neg)\n",
    "importance =list(logistic_model.coef_[0])\n",
    "max_num_index_list = map(importance.index, heapq.nlargest(10, importance))\n",
    "min_num_index_list = map(importance.index, heapq.nsmallest(10,importance))\n",
    "print(\"预测类别1的重要性top10特征索引:\",list(max_num_index_list),\"\\n预测类别0的重要性top10特征索引\",list(min_num_index_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg1=df_neg.loc[[330, 449, 122, 809, 867, 870, 893, 906, 900, 305]]\n",
    "outputpath='C:/Users/RAZER/Desktop/DataPreprocessing_neg1.csv'\n",
    "df_neg1.to_csv(outputpath,sep=',',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统分类算法（pos）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "Logistic_Regression： 0.5\n",
      "Gaussian Navie Bayes:  0.5\n",
      "Support Vector Classifier:  0.5\n",
      "Random Forest Classifier:  0.5\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  0.5\n",
      "Logistic_Regression： 1.0\n",
      "Gaussian Navie Bayes:  1.0\n",
      "Support Vector Classifier:  1.0\n",
      "Random Forest Classifier:  1.0\n",
      "The mean accuracy of Logistic_Regression (positive): 0.9375\n",
      "The mean accuracy of Gaussian Navie Bayes (positive): 0.9375\n",
      "The mean accuracy of Support Vector Classifier (negative): 0.9375\n",
      "The mean accuracy of Random Forest Classifier (negative): 0.875\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=8,shuffle=True)\n",
    "LR_acc=[]\n",
    "GNB_acc=[]\n",
    "SVM_acc=[]\n",
    "RF_acc=[]\n",
    "for train_index, test_index in kf.split(x_pos):\n",
    "#     print(train_index,test_index)\n",
    "    x_pos_train=x_pos.iloc[list(train_index)]\n",
    "    x_pos_test=x_pos.iloc[list(test_index)]\n",
    "    y_pos_train=y_pos.iloc[list(train_index)]\n",
    "    y_pos_test=y_pos.iloc[list(test_index)]\n",
    "#     LR\n",
    "    logistic_model = LogisticRegression(solver=\"liblinear\").fit(x_pos_train, y_pos_train)\n",
    "    logistic_y_pred = logistic_model.predict(x_pos_test)\n",
    "    logistic_acc=accuracy_score(logistic_y_pred, y_pos_test)\n",
    "    print(\"Logistic_Regression：\",logistic_acc)\n",
    "    LR_acc.append(logistic_acc)\n",
    "# 贝叶斯\n",
    "    gaussian_model = GaussianNB().fit(x_pos_train, y_pos_train)\n",
    "    gaussian_y_pred = gaussian_model.predict(x_pos_test)\n",
    "    gaussian_acc=accuracy_score(logistic_y_pred, y_pos_test)\n",
    "    print(\"Gaussian Navie Bayes: \",gaussian_acc)\n",
    "    GNB_acc.append(gaussian_acc)\n",
    "# 支持向量机\n",
    "    svc_model = SVC(kernel=\"linear\").fit(x_pos_train, y_pos_train)\n",
    "    svc_y_pred = svc_model.predict(x_pos_test)\n",
    "    support_vector_acc=accuracy_score(svc_y_pred, y_pos_test)\n",
    "    print(\"Support Vector Classifier: \",support_vector_acc)\n",
    "    SVM_acc.append(support_vector_acc)\n",
    "# Random Forest\n",
    "    randomForest_model = RandomForestClassifier(n_estimators=10).fit(x_pos_train, y_pos_train)\n",
    "    randomForest_y_pred = randomForest_model.predict(x_pos_test)\n",
    "    random_forest_acc=accuracy_score(randomForest_y_pred, y_pos_test)\n",
    "    print(\"Random Forest Classifier: \",random_forest_acc)\n",
    "    RF_acc.append(random_forest_acc)\n",
    "print(\"The mean accuracy of Logistic_Regression (positive):\",np.mean(LR_acc))\n",
    "print(\"The mean accuracy of Gaussian Navie Bayes (positive):\",np.mean(GNB_acc))\n",
    "print(\"The mean accuracy of Support Vector Classifier (negative):\",np.mean(SVM_acc))\n",
    "print(\"The mean accuracy of Random Forest Classifier (negative):\",np.mean(RF_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度权重(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测类别1的重要性top10特征索引: [1588, 1438, 2244, 264, 406, 2225, 1440, 2122, 647, 642] \n",
      "预测类别0的重要性top10特征索引 [643, 458, 363, 366, 592, 2232, 1803, 1110, 639, 1068]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "logistic_model = LogisticRegression(solver=\"liblinear\").fit(x_pos, y_pos)\n",
    "importance =list(logistic_model.coef_[0])\n",
    "max_num_index_list = map(importance.index, heapq.nlargest(10, importance))\n",
    "min_num_index_list = map(importance.index, heapq.nsmallest(10,importance))\n",
    "print(\"预测类别1的重要性top10特征索引:\",list(max_num_index_list),\"\\n预测类别0的重要性top10特征索引\",list(min_num_index_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1=df_pos.loc[[1588, 1438, 2244, 264, 406, 2225, 1440, 2122, 647, 642]]\n",
    "outputpath='C:/Users/RAZER/Desktop/DataPreprocessing_pos1.csv'\n",
    "df_pos1.to_csv(outputpath,sep=',',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
